{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mlflow\n",
    "\n",
    "image_types = ('.jpg', 'jpeg', '.png', '.svg')\n",
    "\n",
    "# Ignore all warnings to clean up log file\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageData():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def read_data_from_dir(self, imagedir, grayscale=True, read_labels=False):\n",
    "        image_files = list()\n",
    "        for file_type in image_types:\n",
    "            image_files.extend(glob.glob(os.path.join(imagedir, \"**/*\" + file_type), recursive=True))\n",
    "        if len(image_files) == 0:\n",
    "            return None\n",
    "        images = []\n",
    "        for each_image_file in image_files:\n",
    "            if grayscale:\n",
    "                img = cv2.imread(each_image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                img = cv2.imread(each_image_file)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        train_x = np.asarray(images)\n",
    "        if read_labels:\n",
    "            csv_files = glob.glob(os.path.join(imagedir, \"**/*\" + \".csv\"), recursive=True)\n",
    "            label_data = pd.read_csv(csv_files[-1])\n",
    "            train_y = label_data.iloc[:,-1:].values\n",
    "            return train_x, train_y\n",
    "        else:\n",
    "            return train_x\n",
    "\n",
    "    def read_classification_data(self, datadir):\n",
    "        train_x = list()\n",
    "        train_y = list()\n",
    "        for dp, dn, filenames in os.walk(datadir):\n",
    "            if len(filenames) > 0:\n",
    "                current_class_data = self.read_data_from_dir(dp)\n",
    "                train_x.extend(current_class_data)\n",
    "                train_y.extend([os.path.basename(dp)] * current_class_data.shape[0])\n",
    "        if len(train_x) == 0:\n",
    "            return None\n",
    "        train_x = np.asarray(train_x)\n",
    "        train_y = np.asarray(train_y)\n",
    "        train_y_classes, train_y = np.unique(train_y, return_inverse=True)\n",
    "        return train_x, (train_y_classes, train_y)\n",
    "\n",
    "    def resize_images(self, images, new_shape):\n",
    "        resized_images = []\n",
    "        for each_image in images:\n",
    "            resized_images.append(cv2.resize(each_image, new_shape, interpolation= cv2.INTER_LINEAR))\n",
    "        resized_images = np.asarray(resized_images)\n",
    "        return resized_images\n",
    "\n",
    "# Set up image variables\n",
    "imd = ImageData()\n",
    "train_x, train_y = imd.read_classification_data(\"/data\")\n",
    "train_y_classes, train_y = train_y\n",
    "resized_train_x = imd.resize_images(train_x, (200,200))\n",
    "resized_train_x = resized_train_x.reshape(resized_train_x.shape[0], 200, 200, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "onehot = encoder.fit_transform(train_y.reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters & MLflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up input hyperparameters\n",
    "NUM_EPOCHS = int(os.getenv(\"EPOCHS\", 5))\n",
    "LEARNING_RATE = args.learning_rate\n",
    "\n",
    "# Set up MLFlow Experiment\n",
    "MLFLOW_EXPERIMENT_NAME = os.getenv('DKUBE_PROJECT_NAME')\n",
    "\n",
    "if MLFLOW_EXPERIMENT_NAME:\n",
    "    exp = mlflow.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)\n",
    "    if not exp:\n",
    "        print(\"Creating experiment...\")\n",
    "        mlflow.create_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "    mlflow.set_experiment(experiment_name=MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFlow metric logging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loggingCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mlflow.log_metric(\"train_loss\", logs[\"loss\"], step=epoch)\n",
    "        mlflow.log_metric (\"train_accuracy\", logs[\"accuracy\"], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", logs[\"val_loss\"], step=epoch)\n",
    "        mlflow.log_metric (\"val_accuracy\", logs[\"val_accuracy\"], step=epoch)\n",
    "        # output accuracy metric for katib to collect from stdout\n",
    "        print(f\"loss={round(logs['loss'],2)}\")\n",
    "        print(f\"val_loss={round(logs['val_loss'],2)}\")\n",
    "        print(f\"accuracy={round(logs['accuracy'],2)}\")\n",
    "        print(f\"val_accuracy={round(logs['val_accuracy'],2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(200,200,1)),\n",
    "  tf.keras.layers.Conv2D(2, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='linear'),\n",
    "  tf.keras.layers.Dense(20, input_dim=5, activation='linear'),\n",
    "  tf.keras.layers.Dense(10, activation='linear'),\n",
    "  tf.keras.layers.Dense(4, activation='linear'),\n",
    "  tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=LEARNING_RATE),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and save metrics & artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLFlow Run\")\n",
    "with mlflow.start_run(run_name=\"xray\") as run:\n",
    "    model.fit(x=resized_train_x, y=onehot, epochs=NUM_EPOCHS, verbose=False, validation_split=0.1, callbacks=[loggingCallback()])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
