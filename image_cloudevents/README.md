# Chest X-Ray Image Monitor Example (Pipeline-Based Workflow)

This example trains a model to identify pneumonia from chest x-rays.  The model is then deployed and used as the basis for monitoring with synthetic live data to demonstrate the DKube monitoring capability.

This workflow uses JupyterLab notebook scripts to set up the resources & create the model monitor, and a Kubeflow pipeline to train & deploy the model.  A separate readme file is available in this folder to create the monitor through the UI, in the same folder called [README-ui.md](README-ui.md)

- This example only supports predict dataset sources as **CloudEvents**. 
- This example  supports model deployment with a full DKube cluster (`serving cluster`) and model monitoring on either the same cluster or a seperate minimal DKube cluster (`monitoring cluster`).
  - **Serving cluster:** Where the production deployment will be running
  - **Monitoring cluster:** Where the model monitor will be running
  > **Note**: The serving and monitoring clusters can be same, but in that case the setup has to be a single **full** DKube setup

## Example Flow

- Create the necessary DKube resources
  - This includes the Code, Dataset and Model repos
- Train a model for the example using Tensorflow
- Deploy the model for serving
- Optionally create a Katib-based hyperparameter run
  - Compare the metrics on the models
- Create a monitor
  - For seperate serving and monitoring clusters
    - Add a serving cluster link on the monitoring cluster
    - Import the deployment onto the monitoring cluster
- Generate data for analysis by the monitor
  - Predict data: Inference inputs/outputs
  - Label data:  Dataset with Groundtruth values for the inferences generated above
  > **Note** In a production environment, the label data would be manually generated by experts in the domain.  In this example, we are creating the labeled data automatically.
- Cleanup the resources after the example is complete

## 1. Create DKube Code Repo

The only manually created resource requirement for this example is the Code repo.  The rest of the resources are optionally created by notebook scripts.

- Select `Code` menu on the left, then `+ Code`, and fill in the following fields:
  - **Name:** `chest-xray`  **(Or choose your own name as `<your-code-repo>`)**
  - **Source:** `Git`
  - **URL:** `https://github.com/oneconvergence/dkube-examples.git`
  - **Branch:** `monitoring`
- Leave the rest of the fields at their current value
- `Add Code` <br><br>
- If you want to have the example automatically perform the training and model deployment, go directly to section [Create and Launch JupyterLab](#3-create-and-launch-jupyterlab)
- If you want to understand the normal setup flow, go to the next section on setting up the rest of the repos

## 2. Create Code and Model Repos

- Select `Datasets` menu on the left, then `+ Dataset`
  - **Name:** `chest-xray`
  - **Source:** `Git`
  - **URL:** `https://github.com/oneconvergence/dkube-examples/tree/monitoring/image_cloudevents/data/chest-xray-mini`
- Leave the rest of the fields at their current value
- `Add Dataset` <br><br>
- Select `Models` menu on the left, then `+ Model`
  - **Name:** `chest-xray`
- Leave the rest of the fields at their current value
- `Add Model`

## 2. Create and Launch JupyterLab

In order to run the script to set up the resources, train and deploy the model, and create the monitor, a JupyterLab IDE needs to be created.  The scripts will be run from within JupyterLab.

- Select `IDE` menu on the left, then `+ JupyterLab`, and fill in the following fields:
  - **Name:** *`<your-IDE-name>`*  **(Choose a name)**
  - **Code:** *`<your-code-repo>`*  **(Chosen during Code repo creation)**
  - **Framework:** `tensorflow`
  - **Framework Version:** `2.0.0`
  - **Image:** `ocdr/dkube-datascience-tf-cpu-multiuser:v2.0.0-17`   **(This should be the default, but ensure that it is selected)**
- Leave the rest of the fields at their current value
- `Submit`

## 3. Create the Resources

This script creates the datasets and models required for training and monitoring.

- Once the IDE is running, launch JupyterLab from the icon on the far right
- Navigate to <code>workspace/**\<your-code-repo\>**/image_cloudevents</code>
- Open `resources.ipynb`
> **Warning** Ensure that `Cleanup = False` in the last cell, since it may have been changed in a previous execution

- If you called your code repo something other than `chest-xray`, edit the following variable in the 3rd cell labeled `User-Defined Variables`:
  - `DKUBE_TRAINING_CODE_NAME` = *`<your-code-repo>`*
 
### Serving and Monitoring on Same Cluster

- If the serving and monitoring cluster are the same, no other fields needs to be changed, skip to [Run the Script](#run-the-script)

### Serving and Monitoring on Different Clusters

- If the monitoring cluster is separate from the serving cluster, you need to provide more information for cluster communication
  - `SERVING_CLUSTER_EXECUTION` = `False`
  - `SERVING_DKUBE_URL` = DKube access URL for the serving cluster, with the form
    - `https://<Serving Cluster Access IP Address>:32222/`
    > **Note** Ensure that there is a final `/` in the URL field
  - `MONITOR_DKUBE_URL `= DKube access URL from the monitoring cluster, with the form
  - `MONITORING_DKUBE_USERNAME` = Username on the monitoring cluster
  - `MONITORING_DKUBE_TOKEN` = Authentication token from the monitoring cluster, from the `Developer Settings` menu
    - `https://<Monitor Cluster Access IP Address>:32222/`
    > **Note** Ensure that there is a final `/` in the URL field
- If the Monitoring cluster already has a link to the Serving cluster from the DKube Clusters Operator screen
  - Get the name of the DKube cluster link and provide that name to the variable `SERVING_DKUBE_CLUSTER_NAME` <br><br>
- If the Monitoring cluster link has not been created by the Operator on the Monitoring cluster:
  - Leave the variable `SERVING_DKUBE_CLUSTER_NAME = ""`
  - In that case, the link will be created on the Monitoring cluster
  - The username identified in the `MONITORING_DKUBE_USERNAME` variable must have Operator privileges for this to work. If not, the script fill fail.
  - Leave the other fields at their current value

### Run the Script

- `Run` > `Run All Cells` from the top menu <br><br>

- The following resources will be created:
  - `chest-xray` Dataset on both the serving and monitoring cluster
  - `<your user name>-image-mm-kf` Model on the serving cluster
  - `<your user name>-image-mm-kf-s3` Dataset on the monitoring cluster

## 4. Train and Deploy the Model on Serving Cluster

This script trains and deploys a model on the serving cluster.  A Kubeflow Pipeline executes this step.

- Open `train-and-deploy.ipynb`
- `Run All Cells`
- This creates and executes a pipeline in order to:
  - Preprocess the dataset and generate the training data or retraining data
  - Train with the generated dataset as an input, and create an output model
  - Deploy the generated model on a predict endpoint
- The pipeline will create a new version of the Model `image-mm-kf`
> **Note** Wait for the pipeline to complete before continuing

## 5. Optional 2nd Model for Metric Comparison

If you want to train a 2nd model in order to compare the metrics, follow the steps in this section.  Otherwise, skip to either [Execute a Katib Run](#6-execute-a-katib-run) or [Create a Model Monitor](#7-create-a-model-monitor).

- Select the `Runs` menu on the left
- Find the most recent Run of the form `xray-pipeline-xxxxxx`
- Select the Run checkbox and `Clone` on the top screen menu
  - Choose a name for your Run
  - Navigate to the `Configuration` tab
  - Select the `+` next to `Environmental variables`
  - Fill in the Key field with `EPOCHS` and the Value field with `20`  (**Note:** The Key field must be in upper case)
- Submit the Run

## 6. Execute a Kabib Run

If you want to execute a Katib run for hyperparameter tuning, follow the steps in this section.  Otherwise, skip to [Create a Model Monitor](#7-create-a-model-monitor).

- Download the hyperparameter tuning file from [Katib Tuning File](https://github.com/oneconvergence/dkube-examples/tree/monitoring/image_cloudevents/xray-tuning.yaml)
  - Select `Raw`
  - Right-click on the file and use `Save as...` <br><br>
- Select the `Runs` menu on the left
- Find the most recent Run of the form `xray-pipeline-xxxxxx`
- Select the Run checkbox and `Clone` on the top menu screen menu
  - Choose a new name for your Run
  - Navigate to the `Configuration` tab
  - Delete any `Environmental variables` using the `X` on the right
    > **note** This step is important, since the Katib run will not work properly with variables active
  - Select the `Upload` button on the `Upload Tuning Definition` section
  - Choose the Katib file that you downloaded
- Submit <br><br>
- When the Run is complete, a single Model will be created with the best trial
- You can view the results by selecting the Katib icon on the far right of the Run

## 7. Create a Model Monitor

In order to monitor the deployed model, a monitor is created and launched.  This workflow executes this programatically through the DKube SDK. This can also be done through the UI by following a different example flow in this repo.

- Open `modelmonitor.ipynb`
 
> **Warning** Ensure that `Cleanup = False` in the last cell, since it may have been changed in a previous execution
 
- `Run all Cells`
- This script will:
  - Add the right links and import the deployment if the monitoring is on a different cluster from the serving cluster
  - Create a new model monitor
- After the script has completed, the monitor `image-mm-kf` will be in the active state

## 8. Generate Data

Predict and Groundtruth datasets will be generated by this script, and will be used by the monitor to analyse the model execution.

- Open `data_generation.ipynb`
- In the 1st cell, update the number of data generation cycles to complete
  - `Run All Cells`
  - This will start to push the data based on the definitions generated in the previous `resources.ipynb` file

> **Note** Live data will be created on the MinIO server under the deployment ID.

## 9. Clean Up the Data when Complete

After you are done with the example, clean up the data by running the `Cleanup` cells in the `modelmonitor` and `resources` scripts

- Set the `Cleanup` variable to `True` in the last cell for each script, select that cell, and `Run Selected Cells` (not all cells)

> **Warning** Ensure that you restore the `Cleanup` variable to `False` after completion, or the scripts will not work on the next execution

<!---
This is from the original readme.  I am leaving it here for reference for enhancements later

4. Open Jupyterlab and from **workspace/monitoring-examples/image_cloudevents** open [resources.ipynb](https://github.com/oneconvergence/dkube-examples/tree/monitoring/image_cloudevents/resources.ipynb) and fill the following details in the first cell.
    - In case of running the example notebook other than the serving setup, In the 1st cell, set RUNNING_IN_SAME to False and Fill the below details,
    - **SERVING_DKUBE_URL** = {DKube url of serving cluster}
    - **SERVING_DKUBE_USERNAME** = {DKube username of serving cluster}
    - **SERVING_DKUBE_TOKEN** = {DKube authentication token of serving cluster}
    - if there is a sperate monitoring cluster then also fill the below details, otherwise leave these value empty.
      - **MONITORING_DKUBE_USERNAME** = {Dkube username of monitoring cluster}
      - **MONITORING_DKUBE_TOKEN** = {DKube authentication token of monitoring cluster}
      - **MONITORING_DKUBE_URL** = {DKube URL of monitoring cluster}
    - **MONITOR_NAME** = {model monitor name}
    - **MINIO_KEY** = {MINIO access key of Dkube setup where the prediction deployment is running}
    - **MINIO_SECRET_KEY** = {MINIO access secret key of Dkube setup where the prediction deployment is running}
      - MINIO_KEY and MINIO_SECRET_KEY values will be filled automatically by the example with SDK call, these values can also be obtained by running the following commands on the DKube setup where the prediction deployment is running. Provide the creds manually if the user is neither PE nor Operator on the remote cluster.
        - DKube API. Fill in DKUBE_IP and TOKEN in the following curl command
          - `curl -X 'GET' \
              'https://DKUBE_IP:32222/dkube/v2/controller/v2/deployments/logstore' \
              -H 'accept: application/json' \
              -H 'Authorization: Bearer <TOKEN>'`
        - If you have access to Kubernetes, you can get the secrets by running the following commands
          - `kubectl get secret -n dkube-infra cloudevents-minio-secret -o jsonpath="{.data.AWS_ACCESS_KEY_ID}" | base64 -d`
          - `kubectl get secret -n dkube-infra cloudevents-minio-secret -o jsonpath="{.data.AWS_SECRET_ACCESS_KEY}" | base64 -d`
    - The following will be derived from the environment automatically if the notebook is running inside same Dkube IDE. Otherwise in case if the notebook is running locally or in other Dkube Setup , then please fill in, 
5. Run all the cells. This will create all the DKube resources required for this example automatically. In case of seperate serving and monitoring cluster, the required resources will be created on the respective cluster.
--->
